{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "Step: 1000,   Loss: 2959386.2500\n",
      "Step: 2000,   Loss: 1347361.5000\n",
      "Step: 3000,   Loss: 607372.0000\n",
      "Step: 4000,   Loss: 362988.2188\n",
      "Step: 5000,   Loss: 306191.7812\n",
      "Step: 6000,   Loss: 274189.0000\n",
      "Step: 7000,   Loss: 233492.9531\n",
      "Step: 8000,   Loss: 185584.4375\n",
      "Step: 9000,   Loss: 136847.5156\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "Step: 11000,   Loss: 58530.1797\n",
      "Step: 12000,   Loss: 33061.9180\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(12001):\n",
    "    if step % 1000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Step: 1000,   Loss: 2959386.2500\n",
      "[[0.9267468  0.9267468  0.9267468  0.9267468  0.9267468  0.9267468 ]\n",
      " [0.91932225 0.91932225 0.91932225 0.91932225 0.91932225 0.91932225]\n",
      " [0.9190366  0.9190366  0.9190366  0.9190366  0.9190366  0.9190366 ]]\n",
      "Step: 2000,   Loss: 1347361.5000\n",
      "[[1.711619  1.711619  1.711619  1.711619  1.711619  1.711619 ]\n",
      " [1.6762273 1.6762273 1.6762273 1.6762273 1.6762273 1.6762273]\n",
      " [1.6748521 1.6748521 1.6748521 1.6748521 1.6748521 1.6748521]]\n",
      "Step: 3000,   Loss: 607372.0000\n",
      "[[2.3572354 2.3572354 2.3572354 2.3572354 2.3572354 2.3572354]\n",
      " [2.2568073 2.2568073 2.2568073 2.2568073 2.2568073 2.2568073]\n",
      " [2.2528458 2.2528458 2.2528458 2.2528458 2.2528458 2.2528458]]\n",
      "Step: 4000,   Loss: 362988.2188\n",
      "[[2.859727  2.859727  2.859727  2.859727  2.859727  2.859727 ]\n",
      " [2.6197753 2.6197753 2.6197753 2.6197753 2.6197753 2.6197753]\n",
      " [2.61014   2.61014   2.61014   2.61014   2.61014   2.61014  ]]\n",
      "Step: 5000,   Loss: 306191.7812\n",
      "[[3.2492604 3.2492604 3.2492604 3.2492604 3.2492604 3.2492604]\n",
      " [2.7317991 2.7317991 2.7317991 2.7317991 2.7317991 2.7317991]\n",
      " [2.7110572 2.7110572 2.7110572 2.7110572 2.7110572 2.7110572]]\n",
      "Step: 6000,   Loss: 274189.0000\n",
      "[[3.6347997 3.6347997 3.6347997 3.6347997 3.6347997 3.6347997]\n",
      " [2.6424525 2.6424525 2.6424525 2.6424525 2.6424525 2.6424525]\n",
      " [2.6048608 2.6048608 2.6048608 2.6048608 2.6048608 2.6048608]]\n",
      "Step: 7000,   Loss: 233492.9531\n",
      "[[4.1359143 4.1359143 4.1359143 4.1359143 4.1359143 4.1359143]\n",
      " [2.4449887 2.4449887 2.4449887 2.4449887 2.4449887 2.4449887]\n",
      " [2.3889806 2.3889806 2.3889806 2.3889806 2.3889806 2.3889806]]\n",
      "Step: 8000,   Loss: 185584.4375\n",
      "[[4.7829304 4.7829304 4.7829304 4.7829304 4.7829304 4.7829304]\n",
      " [2.178528  2.178528  2.178528  2.178528  2.178528  2.178528 ]\n",
      " [2.1103806 2.1103806 2.1103806 2.1103806 2.1103806 2.1103806]]\n",
      "Step: 9000,   Loss: 136847.5156\n",
      "[[5.5361147 5.5361147 5.5361147 5.5361147 5.5361147 5.5361147]\n",
      " [1.8627863 1.8627863 1.8627863 1.8627863 1.8627863 1.8627863]\n",
      " [1.7982405 1.7982405 1.7982405 1.7982405 1.7982405 1.7982405]]\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "[[6.3351717 6.3351717 6.3351717 6.3351717 6.3351717 6.3351717]\n",
      " [1.522709  1.522709  1.522709  1.522709  1.522709  1.522709 ]\n",
      " [1.482626  1.482626  1.482626  1.482626  1.482626  1.482626 ]]\n",
      "Step: 11000,   Loss: 58530.1797\n",
      "[[7.1309505 7.1309505 7.1309505 7.1309505 7.1309505 7.1309505]\n",
      " [1.1808001 1.1808001 1.1808001 1.1808001 1.1808001 1.1808001]\n",
      " [1.1813059 1.1813059 1.1813059 1.1813059 1.1813059 1.1813059]]\n",
      "Step: 12000,   Loss: 33061.9180\n",
      "[[7.890447   7.890447   7.890447   7.890447   7.890447   7.890447  ]\n",
      " [0.8547127  0.8547127  0.8547127  0.8547127  0.8547127  0.8547127 ]\n",
      " [0.89990735 0.89990735 0.89990735 0.89990735 0.89990735 0.89990735]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(12001):\n",
    "    if step % 1000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "        print(w_val)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# # 線形回帰予測関数\n",
    "# def predict(x):\n",
    "#     result = 0.0\n",
    "#     for n in range(0,5):\n",
    "#         result += w_val[n][0] * x**n\n",
    "#     return result\n",
    "\n",
    "# fig = plt.figure()\n",
    "# subplot = fig.add_subplot(1,1,1)\n",
    "\n",
    "# plt.scatter(x_data,y_data)\n",
    "# linex = np.linspace(0,1,100)\n",
    "# liney = predict(linex)\n",
    "# subplot.plot(linex,liney)\n",
    "# plt.show()\n",
    "\n",
    "# tf.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Step: 1000,   Loss: 2959386.2500\n",
      "[[0.9267468  0.9267468  0.9267468  0.9267468  0.9267468  0.9267468 ]\n",
      " [0.91932225 0.91932225 0.91932225 0.91932225 0.91932225 0.91932225]\n",
      " [0.9190366  0.9190366  0.9190366  0.9190366  0.9190366  0.9190366 ]]\n",
      "Step: 2000,   Loss: 1347361.5000\n",
      "[[1.711619  1.711619  1.711619  1.711619  1.711619  1.711619 ]\n",
      " [1.6762273 1.6762273 1.6762273 1.6762273 1.6762273 1.6762273]\n",
      " [1.6748521 1.6748521 1.6748521 1.6748521 1.6748521 1.6748521]]\n",
      "Step: 3000,   Loss: 607372.0000\n",
      "[[2.3572354 2.3572354 2.3572354 2.3572354 2.3572354 2.3572354]\n",
      " [2.2568073 2.2568073 2.2568073 2.2568073 2.2568073 2.2568073]\n",
      " [2.2528458 2.2528458 2.2528458 2.2528458 2.2528458 2.2528458]]\n",
      "Step: 4000,   Loss: 362988.2188\n",
      "[[2.859727  2.859727  2.859727  2.859727  2.859727  2.859727 ]\n",
      " [2.6197753 2.6197753 2.6197753 2.6197753 2.6197753 2.6197753]\n",
      " [2.61014   2.61014   2.61014   2.61014   2.61014   2.61014  ]]\n",
      "Step: 5000,   Loss: 306191.7812\n",
      "[[3.2492604 3.2492604 3.2492604 3.2492604 3.2492604 3.2492604]\n",
      " [2.7317991 2.7317991 2.7317991 2.7317991 2.7317991 2.7317991]\n",
      " [2.7110572 2.7110572 2.7110572 2.7110572 2.7110572 2.7110572]]\n",
      "Step: 6000,   Loss: 274189.0000\n",
      "[[3.6347997 3.6347997 3.6347997 3.6347997 3.6347997 3.6347997]\n",
      " [2.6424525 2.6424525 2.6424525 2.6424525 2.6424525 2.6424525]\n",
      " [2.6048608 2.6048608 2.6048608 2.6048608 2.6048608 2.6048608]]\n",
      "Step: 7000,   Loss: 233492.9531\n",
      "[[4.1359143 4.1359143 4.1359143 4.1359143 4.1359143 4.1359143]\n",
      " [2.4449887 2.4449887 2.4449887 2.4449887 2.4449887 2.4449887]\n",
      " [2.3889806 2.3889806 2.3889806 2.3889806 2.3889806 2.3889806]]\n",
      "Step: 8000,   Loss: 185584.4375\n",
      "[[4.7829304 4.7829304 4.7829304 4.7829304 4.7829304 4.7829304]\n",
      " [2.178528  2.178528  2.178528  2.178528  2.178528  2.178528 ]\n",
      " [2.1103806 2.1103806 2.1103806 2.1103806 2.1103806 2.1103806]]\n",
      "Step: 9000,   Loss: 136847.5156\n",
      "[[5.5361147 5.5361147 5.5361147 5.5361147 5.5361147 5.5361147]\n",
      " [1.8627863 1.8627863 1.8627863 1.8627863 1.8627863 1.8627863]\n",
      " [1.7982405 1.7982405 1.7982405 1.7982405 1.7982405 1.7982405]]\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "[[6.3351717 6.3351717 6.3351717 6.3351717 6.3351717 6.3351717]\n",
      " [1.522709  1.522709  1.522709  1.522709  1.522709  1.522709 ]\n",
      " [1.482626  1.482626  1.482626  1.482626  1.482626  1.482626 ]]\n",
      "Step: 11000,   Loss: 58530.1797\n",
      "[[7.1309505 7.1309505 7.1309505 7.1309505 7.1309505 7.1309505]\n",
      " [1.1808001 1.1808001 1.1808001 1.1808001 1.1808001 1.1808001]\n",
      " [1.1813059 1.1813059 1.1813059 1.1813059 1.1813059 1.1813059]]\n",
      "Step: 12000,   Loss: 33061.9180\n",
      "[[7.890447   7.890447   7.890447   7.890447   7.890447   7.890447  ]\n",
      " [0.8547127  0.8547127  0.8547127  0.8547127  0.8547127  0.8547127 ]\n",
      " [0.89990735 0.89990735 0.89990735 0.89990735 0.89990735 0.89990735]]\n",
      "Step: 13000,   Loss: 16391.3418\n",
      "[[8.587048   8.587048   8.587048   8.587048   8.587048   8.587048  ]\n",
      " [0.5584358  0.5584358  0.5584358  0.5584358  0.5584358  0.5584358 ]\n",
      " [0.64308196 0.64308196 0.64308196 0.64308196 0.64308196 0.64308196]]\n",
      "Step: 14000,   Loss: 7095.8584\n",
      "[[9.190278   9.190278   9.190278   9.190278   9.190278   9.190278  ]\n",
      " [0.30610213 0.30610213 0.30610213 0.30610213 0.30610213 0.30610213]\n",
      " [0.42129725 0.42129725 0.42129725 0.42129725 0.42129725 0.42129725]]\n",
      "Step: 15000,   Loss: 3081.9302\n",
      "[[9.660729   9.660729   9.660729   9.660729   9.660729   9.660729  ]\n",
      " [0.1167836  0.1167836  0.1167836  0.1167836  0.1167836  0.1167836 ]\n",
      " [0.25022572 0.25022572 0.25022572 0.25022572 0.25022572 0.25022572]]\n",
      "Step: 16000,   Loss: 1888.5520\n",
      "[[9.9602957e+00 9.9602957e+00 9.9602957e+00 9.9602957e+00 9.9602957e+00\n",
      "  9.9602957e+00]\n",
      " [6.2631192e-03 6.2631192e-03 6.2631192e-03 6.2631192e-03 6.2631192e-03\n",
      "  6.2631192e-03]\n",
      " [1.4392076e-01 1.4392076e-01 1.4392076e-01 1.4392076e-01 1.4392076e-01\n",
      "  1.4392076e-01]]\n",
      "Step: 17000,   Loss: 1616.0997\n",
      "[[10.092013   10.092013   10.092013   10.092013   10.092013   10.092013  ]\n",
      " [-0.03356149 -0.03356149 -0.03356149 -0.03356149 -0.03356149 -0.03356149]\n",
      " [ 0.09963163  0.09963163  0.09963163  0.09963163  0.09963163  0.09963163]]\n",
      "Step: 18000,   Loss: 1490.2961\n",
      "[[10.13013    10.13013    10.13013    10.13013    10.13013    10.13013   ]\n",
      " [-0.03601165 -0.03601165 -0.03601165 -0.03601165 -0.03601165 -0.03601165]\n",
      " [ 0.08947702  0.08947702  0.08947702  0.08947702  0.08947702  0.08947702]]\n",
      "Step: 19000,   Loss: 1387.6528\n",
      "[[10.146414   10.146414   10.146414   10.146414   10.146414   10.146414  ]\n",
      " [-0.03036938 -0.03036938 -0.03036938 -0.03036938 -0.03036938 -0.03036938]\n",
      " [ 0.08713154  0.08713154  0.08713154  0.08713154  0.08713154  0.08713154]]\n",
      "Step: 20000,   Loss: 1298.2266\n",
      "[[10.160319   10.160319   10.160319   10.160319   10.160319   10.160319  ]\n",
      " [-0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206]\n",
      " [ 0.0855459   0.0855459   0.0855459   0.0855459   0.0855459   0.0855459 ]]\n",
      "Step: 21000,   Loss: 1219.7228\n",
      "[[10.173542   10.173542   10.173542   10.173542   10.173542   10.173542  ]\n",
      " [-0.01801451 -0.01801451 -0.01801451 -0.01801451 -0.01801451 -0.01801451]\n",
      " [ 0.08414527  0.08414527  0.08414527  0.08414527  0.08414527  0.08414527]]\n",
      "Step: 22000,   Loss: 1151.2612\n",
      "[[10.186284   10.186284   10.186284   10.186284   10.186284   10.186284  ]\n",
      " [-0.01183502 -0.01183502 -0.01183502 -0.01183502 -0.01183502 -0.01183502]\n",
      " [ 0.08286643  0.08286643  0.08286643  0.08286643  0.08286643  0.08286643]]\n",
      "Step: 23000,   Loss: 1092.3977\n",
      "[[ 1.0198713e+01  1.0198713e+01  1.0198713e+01  1.0198713e+01\n",
      "   1.0198713e+01  1.0198713e+01]\n",
      " [-5.7290532e-03 -5.7290532e-03 -5.7290532e-03 -5.7290532e-03\n",
      "  -5.7290532e-03 -5.7290532e-03]\n",
      " [ 8.1647173e-02  8.1647173e-02  8.1647173e-02  8.1647173e-02\n",
      "   8.1647173e-02  8.1647173e-02]]\n",
      "Step: 24000,   Loss: 1042.7823\n",
      "[[1.0210805e+01 1.0210805e+01 1.0210805e+01 1.0210805e+01 1.0210805e+01\n",
      "  1.0210805e+01]\n",
      " [2.8405825e-04 2.8405825e-04 2.8405825e-04 2.8405825e-04 2.8405825e-04\n",
      "  2.8405825e-04]\n",
      " [8.0484524e-02 8.0484524e-02 8.0484524e-02 8.0484524e-02 8.0484524e-02\n",
      "  8.0484524e-02]]\n",
      "Step: 25000,   Loss: 1002.1230\n",
      "[[1.0222547e+01 1.0222547e+01 1.0222547e+01 1.0222547e+01 1.0222547e+01\n",
      "  1.0222547e+01]\n",
      " [6.1541311e-03 6.1541311e-03 6.1541311e-03 6.1541311e-03 6.1541311e-03\n",
      "  6.1541311e-03]\n",
      " [7.9364881e-02 7.9364881e-02 7.9364881e-02 7.9364881e-02 7.9364881e-02\n",
      "  7.9364881e-02]]\n",
      "Step: 26000,   Loss: 970.0402\n",
      "[[10.233869   10.233869   10.233869   10.233869   10.233869   10.233869  ]\n",
      " [ 0.0118306   0.0118306   0.0118306   0.0118306   0.0118306   0.0118306 ]\n",
      " [ 0.07829238  0.07829238  0.07829238  0.07829238  0.07829238  0.07829238]]\n",
      "Step: 27000,   Loss: 946.0311\n",
      "[[10.244636   10.244636   10.244636   10.244636   10.244636   10.244636  ]\n",
      " [ 0.01722657  0.01722657  0.01722657  0.01722657  0.01722657  0.01722657]\n",
      " [ 0.07725901  0.07725901  0.07725901  0.07725901  0.07725901  0.07725901]]\n",
      "Step: 28000,   Loss: 929.4431\n",
      "[[10.254653   10.254653   10.254653   10.254653   10.254653   10.254653  ]\n",
      " [ 0.02226472  0.02226472  0.02226472  0.02226472  0.02226472  0.02226472]\n",
      " [ 0.07631145  0.07631145  0.07631145  0.07631145  0.07631145  0.07631145]]\n",
      "Step: 29000,   Loss: 919.3070\n",
      "[[10.263639   10.263639   10.263639   10.263639   10.263639   10.263639  ]\n",
      " [ 0.02684755  0.02684755  0.02684755  0.02684755  0.02684755  0.02684755]\n",
      " [ 0.07554624  0.07554624  0.07554624  0.07554624  0.07554624  0.07554624]]\n",
      "Step: 30000,   Loss: 914.2769\n",
      "[[10.271035   10.271035   10.271035   10.271035   10.271035   10.271035  ]\n",
      " [ 0.03055731  0.03055731  0.03055731  0.03055731  0.03055731  0.03055731]\n",
      " [ 0.07483479  0.07483479  0.07483479  0.07483479  0.07483479  0.07483479]]\n",
      "Step: 31000,   Loss: 912.5428\n",
      "[[10.276205   10.276205   10.276205   10.276205   10.276205   10.276205  ]\n",
      " [ 0.03313879  0.03313879  0.03313879  0.03313879  0.03313879  0.03313879]\n",
      " [ 0.07430701  0.07430701  0.07430701  0.07430701  0.07430701  0.07430701]]\n",
      "Step: 32000,   Loss: 912.2413\n",
      "[[10.278856   10.278856   10.278856   10.278856   10.278856   10.278856  ]\n",
      " [ 0.03448796  0.03448796  0.03448796  0.03448796  0.03448796  0.03448796]\n",
      " [ 0.07408356  0.07408356  0.07408356  0.07408356  0.07408356  0.07408356]]\n",
      "Step: 33000,   Loss: 912.2232\n",
      "[[10.2795     10.2795     10.2795     10.2795     10.2795     10.2795    ]\n",
      " [ 0.03477783  0.03477783  0.03477783  0.03477783  0.03477783  0.03477783]\n",
      " [ 0.07395049  0.07395049  0.07395049  0.07395049  0.07395049  0.07395049]]\n",
      "Step: 34000,   Loss: 912.2238\n",
      "[[10.279618   10.279618   10.279618   10.279618   10.279618   10.279618  ]\n",
      " [ 0.03486109  0.03486109  0.03486109  0.03486109  0.03486109  0.03486109]\n",
      " [ 0.0739952   0.0739952   0.0739952   0.0739952   0.0739952   0.0739952 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 35000,   Loss: 912.2168\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279606   10.279606  ]\n",
      " [ 0.03485268  0.03485268  0.03485268  0.03485268  0.03485268  0.03485268]\n",
      " [ 0.07398507  0.07398507  0.07398507  0.07398507  0.07398507  0.07398507]]\n",
      "Step: 36000,   Loss: 912.2197\n",
      "[[10.279592   10.279592   10.279592   10.279592   10.279592   10.279592  ]\n",
      " [ 0.03483735  0.03483735  0.03483735  0.03483735  0.03483735  0.03483735]\n",
      " [ 0.07397119  0.07397119  0.07397119  0.07397119  0.07397119  0.07397119]]\n",
      "Step: 37000,   Loss: 912.2227\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279609   10.279609  ]\n",
      " [ 0.03485418  0.03485418  0.03485418  0.03485418  0.03485418  0.03485418]\n",
      " [ 0.07398649  0.07398649  0.07398649  0.07398649  0.07398649  0.07398649]]\n",
      "Step: 38000,   Loss: 912.2244\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279609   10.279609  ]\n",
      " [ 0.034853    0.034853    0.034853    0.034853    0.034853    0.034853  ]\n",
      " [ 0.07398617  0.07398617  0.07398617  0.07398617  0.07398617  0.07398617]]\n",
      "Step: 39000,   Loss: 912.2249\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279613   10.279613  ]\n",
      " [ 0.03485695  0.03485695  0.03485695  0.03485695  0.03485695  0.03485695]\n",
      " [ 0.07399034  0.07399034  0.07399034  0.07399034  0.07399034  0.07399034]]\n",
      "Step: 40000,   Loss: 912.2196\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279606   10.279606  ]\n",
      " [ 0.03485141  0.03485141  0.03485141  0.03485141  0.03485141  0.03485141]\n",
      " [ 0.07398419  0.07398419  0.07398419  0.07398419  0.07398419  0.07398419]]\n",
      "Step: 41000,   Loss: 912.2224\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.2796     10.2796    ]\n",
      " [ 0.03485307  0.03485307  0.03485307  0.03485307  0.03484465  0.03484465]\n",
      " [ 0.0739859   0.0739859   0.0739859   0.0739859   0.07397778  0.07397778]]\n",
      "Step: 42000,   Loss: 912.2273\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.2796     10.2796    ]\n",
      " [ 0.0348566   0.0348566   0.0348566   0.0348566   0.03484577  0.03484577]\n",
      " [ 0.07398922  0.07398922  0.07398922  0.07398922  0.07397858  0.07397858]]\n",
      "Step: 43000,   Loss: 912.2278\n",
      "[[10.279625   10.279625   10.279625   10.279625   10.279615   10.279615  ]\n",
      " [ 0.03487034  0.03487034  0.03487034  0.03487034  0.03486152  0.03486152]\n",
      " [ 0.07400315  0.07400315  0.07400315  0.07400315  0.07399455  0.07399455]]\n",
      "Step: 44000,   Loss: 912.2230\n",
      "[[10.279657   10.279657   10.279657   10.279657   10.279617   10.279617  ]\n",
      " [ 0.03490258  0.03490258  0.03490258  0.03490258  0.03486204  0.03486204]\n",
      " [ 0.07403567  0.07403567  0.07403567  0.07403567  0.07399557  0.07399557]]\n",
      "Step: 45000,   Loss: 912.2233\n",
      "[[10.279591   10.279591   10.279591   10.279591   10.279616   10.279616  ]\n",
      " [ 0.0348346   0.0348346   0.0348346   0.0348346   0.03486113  0.03486113]\n",
      " [ 0.07396635  0.07396635  0.07396635  0.07396635  0.0739938   0.0739938 ]]\n",
      "Step: 46000,   Loss: 912.2234\n",
      "[[10.279601   10.279601   10.279601   10.279601   10.279604   10.279604  ]\n",
      " [ 0.03484466  0.03484466  0.03484466  0.03484466  0.03484933  0.03484933]\n",
      " [ 0.07397719  0.07397719  0.07397719  0.07397719  0.07398246  0.07398246]]\n",
      "Step: 47000,   Loss: 912.2252\n",
      "[[10.279612   10.279612   10.279612   10.279612   10.279662   10.279662  ]\n",
      " [ 0.03485654  0.03485654  0.03485654  0.03485654  0.0349064   0.0349064 ]\n",
      " [ 0.07398985  0.07398985  0.07398985  0.07398985  0.07403966  0.07403966]]\n",
      "Step: 48000,   Loss: 912.2203\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279606   10.279606  ]\n",
      " [ 0.0348539   0.0348539   0.0348539   0.0348539   0.03485068  0.03485068]\n",
      " [ 0.07398675  0.07398675  0.07398675  0.07398675  0.07398347  0.07398347]]\n",
      "Step: 49000,   Loss: 912.2234\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279598   10.279598  ]\n",
      " [ 0.03485351  0.03485351  0.03485351  0.03485351  0.03484385  0.03484385]\n",
      " [ 0.07398641  0.07398641  0.07398641  0.07398641  0.07397714  0.07397714]]\n",
      "Step: 50000,   Loss: 912.2220\n",
      "[[10.279614   10.279614   10.279614   10.279614   10.279593   10.279593  ]\n",
      " [ 0.0348593   0.0348593   0.0348593   0.0348593   0.03483845  0.03483845]\n",
      " [ 0.07399281  0.07399281  0.07399281  0.07399281  0.07397114  0.07397114]]\n",
      "Step: 51000,   Loss: 912.2234\n",
      "[[10.2796     10.2796     10.2796     10.2796     10.279628   10.279628  ]\n",
      " [ 0.03484498  0.03484498  0.03484498  0.03484498  0.03487223  0.03487223]\n",
      " [ 0.0739779   0.0739779   0.0739779   0.0739779   0.07400482  0.07400482]]\n",
      "Step: 52000,   Loss: 912.2224\n",
      "[[10.279612   10.279612   10.279612   10.279612   10.279608   10.279608  ]\n",
      " [ 0.0348573   0.0348573   0.0348573   0.0348573   0.03485192  0.03485192]\n",
      " [ 0.07399     0.07399     0.07399     0.07399     0.07398531  0.07398531]]\n",
      "Step: 53000,   Loss: 912.2198\n",
      "[[10.27962    10.27962    10.27962    10.27962    10.279605   10.279605  ]\n",
      " [ 0.03486569  0.03486569  0.03486569  0.03486569  0.03484892  0.03484892]\n",
      " [ 0.07399867  0.07399867  0.07399867  0.07399867  0.07398164  0.07398164]]\n",
      "Step: 54000,   Loss: 912.2231\n",
      "[[10.27964    10.27964    10.27964    10.27964    10.279598   10.279598  ]\n",
      " [ 0.03488455  0.03488455  0.03488455  0.03488455  0.03484309  0.03484309]\n",
      " [ 0.07401669  0.07401669  0.07401669  0.07401669  0.07397565  0.07397565]]\n",
      "Step: 55000,   Loss: 912.2201\n",
      "[[10.279622   10.279622   10.279622   10.279622   10.279603   10.279603  ]\n",
      " [ 0.03486503  0.03486503  0.03486503  0.03486503  0.03484764  0.03484764]\n",
      " [ 0.07399853  0.07399853  0.07399853  0.07399853  0.07398065  0.07398065]]\n",
      "Step: 56000,   Loss: 912.2215\n",
      "[[10.279589   10.279589   10.279589   10.279589   10.279606   10.279606  ]\n",
      " [ 0.03483352  0.03483352  0.03483352  0.03483352  0.03485239  0.03485239]\n",
      " [ 0.073966    0.073966    0.073966    0.073966    0.0739848   0.0739848 ]]\n",
      "Step: 57000,   Loss: 912.2181\n",
      "[[10.279591   10.279591   10.279591   10.279591   10.279614   10.279614  ]\n",
      " [ 0.0348364   0.0348364   0.0348364   0.0348364   0.03486001  0.03486001]\n",
      " [ 0.07396835  0.07396835  0.07396835  0.07396835  0.07399282  0.07399282]]\n",
      "Step: 58000,   Loss: 912.2250\n",
      "[[10.27958    10.27958    10.27958    10.27958    10.279571   10.279571  ]\n",
      " [ 0.03482505  0.03482505  0.03482505  0.03482505  0.03481407  0.03481407]\n",
      " [ 0.07395843  0.07395843  0.07395843  0.07395843  0.07394741  0.07394741]]\n",
      "Step: 59000,   Loss: 912.2201\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279603   10.279603  ]\n",
      " [ 0.03485438  0.03485438  0.03485438  0.03485438  0.03484759  0.03484759]\n",
      " [ 0.07398759  0.07398759  0.07398759  0.07398759  0.07398017  0.07398017]]\n",
      "Step: 60000,   Loss: 912.2256\n",
      "[[10.279628   10.279628   10.279628   10.279628   10.2796135  10.2796135 ]\n",
      " [ 0.0348731   0.0348731   0.0348731   0.0348731   0.0348588   0.0348588 ]\n",
      " [ 0.07400642  0.07400642  0.07400642  0.07400642  0.07399222  0.07399222]]\n",
      "Step: 61000,   Loss: 912.2178\n",
      "[[10.279578   10.279578   10.279578   10.279578   10.2796     10.2796    ]\n",
      " [ 0.03482424  0.03482424  0.03482424  0.03482424  0.03484535  0.03484535]\n",
      " [ 0.07395723  0.07395723  0.07395723  0.07395723  0.07397728  0.07397728]]\n",
      "Step: 62000,   Loss: 912.2202\n",
      "[[10.279619   10.279619   10.279619   10.279619   10.27959    10.27959   ]\n",
      " [ 0.03486296  0.03486296  0.03486296  0.03486296  0.03483348  0.03483348]\n",
      " [ 0.07399543  0.07399543  0.07399543  0.07399543  0.07396696  0.07396696]]\n",
      "Step: 63000,   Loss: 912.2239\n",
      "[[10.279675   10.279675   10.279675   10.279675   10.279601   10.279601  ]\n",
      " [ 0.0349186   0.0349186   0.0349186   0.0349186   0.03484701  0.03484701]\n",
      " [ 0.07405151  0.07405151  0.07405151  0.07405151  0.07398101  0.07398101]]\n",
      "Step: 64000,   Loss: 912.2213\n",
      "[[10.279618   10.279618   10.279618   10.279618   10.279611   10.279611  ]\n",
      " [ 0.03486418  0.03486418  0.03486418  0.03486418  0.03485503  0.03485503]\n",
      " [ 0.07399768  0.07399768  0.07399768  0.07399768  0.07398769  0.07398769]]\n",
      "Step: 65000,   Loss: 912.2200\n",
      "[[10.279559   10.279559   10.279559   10.279559   10.279586   10.279586  ]\n",
      " [ 0.03480333  0.03480333  0.03480333  0.03480333  0.03482991  0.03482991]\n",
      " [ 0.07393622  0.07393622  0.07393622  0.07393622  0.07396266  0.07396266]]\n",
      "Step: 66000,   Loss: 912.2218\n",
      "[[10.279596   10.279596   10.279596   10.279596   10.279599   10.279599  ]\n",
      " [ 0.03484256  0.03484256  0.03484256  0.03484256  0.0348452   0.0348452 ]\n",
      " [ 0.07397488  0.07397488  0.07397488  0.07397488  0.07397804  0.07397804]]\n",
      "Step: 67000,   Loss: 912.2242\n",
      "[[10.2795925  10.2795925  10.2795925  10.2795925  10.279618   10.279618  ]\n",
      " [ 0.0348374   0.0348374   0.0348374   0.0348374   0.0348625   0.0348625 ]\n",
      " [ 0.07397016  0.07397016  0.07397016  0.07397016  0.07399563  0.07399563]]\n",
      "Step: 68000,   Loss: 912.2208\n",
      "[[10.279569   10.279569   10.279569   10.279569   10.279656   10.279656  ]\n",
      " [ 0.03481258  0.03481258  0.03481258  0.03481258  0.0349015   0.0349015 ]\n",
      " [ 0.07394525  0.07394525  0.07394525  0.07394525  0.07403345  0.07403345]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 69000,   Loss: 912.2197\n",
      "[[10.2796     10.2796     10.2796     10.2796     10.279621   10.279621  ]\n",
      " [ 0.03484476  0.03484476  0.03484476  0.03484476  0.03486468  0.03486468]\n",
      " [ 0.07397818  0.07397818  0.07397818  0.07397818  0.0739977   0.0739977 ]]\n",
      "Step: 70000,   Loss: 912.2224\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279614   10.279614  ]\n",
      " [ 0.03485594  0.03485594  0.03485594  0.03485594  0.03485974  0.03485974]\n",
      " [ 0.07398903  0.07398903  0.07398903  0.07398903  0.07399241  0.07399241]]\n",
      "Step: 71000,   Loss: 912.2212\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279611   10.279611  ]\n",
      " [ 0.03485471  0.03485471  0.03485471  0.03485471  0.03485698  0.03485698]\n",
      " [ 0.07398823  0.07398823  0.07398823  0.07398823  0.07398997  0.07398997]]\n",
      "Step: 72000,   Loss: 912.2230\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.2796135  10.2796135 ]\n",
      " [ 0.03485708  0.03485708  0.03485708  0.03485708  0.03485781  0.03485781]\n",
      " [ 0.07398982  0.07398982  0.07398982  0.07398982  0.07399131  0.07399131]]\n",
      "Step: 73000,   Loss: 912.2223\n",
      "[[10.279615   10.279615   10.279615   10.279615   10.279603   10.279603  ]\n",
      " [ 0.03485968  0.03485968  0.03485968  0.03485968  0.03484903  0.03484903]\n",
      " [ 0.07399273  0.07399273  0.07399273  0.07399273  0.07398134  0.07398134]]\n",
      "Step: 74000,   Loss: 912.2223\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279614   10.279614  ]\n",
      " [ 0.0348562   0.0348562   0.0348562   0.0348562   0.03485939  0.03485939]\n",
      " [ 0.07398909  0.07398909  0.07398909  0.07398909  0.07399121  0.07399121]]\n",
      "Step: 75000,   Loss: 912.2199\n",
      "[[10.279605   10.279605   10.279605   10.279605   10.279612   10.279612  ]\n",
      " [ 0.03485215  0.03485215  0.03485215  0.03485215  0.03485706  0.03485706]\n",
      " [ 0.07398535  0.07398535  0.07398535  0.07398535  0.07398923  0.07398923]]\n",
      "Step: 76000,   Loss: 912.2229\n",
      "[[10.2795925  10.2795925  10.2795925  10.2795925  10.279617   10.279617  ]\n",
      " [ 0.03483711  0.03483711  0.03483711  0.03483711  0.0348626   0.0348626 ]\n",
      " [ 0.07397102  0.07397102  0.07397102  0.07397102  0.07399464  0.07399464]]\n",
      "Step: 77000,   Loss: 912.2261\n",
      "[[10.2796135  10.2796135  10.2796135  10.2796135  10.279597   10.279597  ]\n",
      " [ 0.03485929  0.03485929  0.03485929  0.03485929  0.03484371  0.03484371]\n",
      " [ 0.07399331  0.07399331  0.07399331  0.07399331  0.07397638  0.07397638]]\n",
      "Step: 78000,   Loss: 912.2221\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279612   10.279612  ]\n",
      " [ 0.03485286  0.03485286  0.03485286  0.03485286  0.03485671  0.03485671]\n",
      " [ 0.07398639  0.07398639  0.07398639  0.07398639  0.07398973  0.07398973]]\n",
      "Step: 79000,   Loss: 912.2283\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279612   10.279612  ]\n",
      " [ 0.03485426  0.03485426  0.03485426  0.03485426  0.03485621  0.03485621]\n",
      " [ 0.07398739  0.07398739  0.07398739  0.07398739  0.07398843  0.07398843]]\n",
      "Step: 80000,   Loss: 912.2250\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279569   10.279569  ]\n",
      " [ 0.03485684  0.03485684  0.03485684  0.03485684  0.03481402  0.03481402]\n",
      " [ 0.07398963  0.07398963  0.07398963  0.07398963  0.07394752  0.07394752]]\n",
      "Step: 81000,   Loss: 912.2224\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279592   10.279592  ]\n",
      " [ 0.03485217  0.03485217  0.03485217  0.03485217  0.03483545  0.03483545]\n",
      " [ 0.07398552  0.07398552  0.07398552  0.07398552  0.07396812  0.07396812]]\n",
      "Step: 82000,   Loss: 912.2221\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279601   10.279601  ]\n",
      " [ 0.03485524  0.03485524  0.03485524  0.03485524  0.03484682  0.03484682]\n",
      " [ 0.07398827  0.07398827  0.07398827  0.07398827  0.07397956  0.07397956]]\n",
      "Step: 83000,   Loss: 912.2193\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279581   10.279581  ]\n",
      " [ 0.03485395  0.03485395  0.03485395  0.03485395  0.03482669  0.03482669]\n",
      " [ 0.07398663  0.07398663  0.07398663  0.07398663  0.07395893  0.07395893]]\n",
      "Step: 84000,   Loss: 912.2223\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279609   10.279609  ]\n",
      " [ 0.0348551   0.0348551   0.0348551   0.0348551   0.03485418  0.03485418]\n",
      " [ 0.07398793  0.07398793  0.07398793  0.07398793  0.07398725  0.07398725]]\n",
      "Step: 85000,   Loss: 912.2211\n",
      "[[10.279596   10.279596   10.279596   10.279596   10.279636   10.279636  ]\n",
      " [ 0.03484255  0.03484255  0.03484255  0.03484255  0.03488148  0.03488148]\n",
      " [ 0.07397536  0.07397536  0.07397536  0.07397536  0.07401362  0.07401362]]\n",
      "Step: 86000,   Loss: 912.2207\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.2796     10.2796    ]\n",
      " [ 0.03485492  0.03485492  0.03485492  0.03485492  0.0348473   0.0348473 ]\n",
      " [ 0.07398728  0.07398728  0.07398728  0.07398728  0.07397892  0.07397892]]\n",
      "Step: 87000,   Loss: 912.2239\n",
      "[[10.279599   10.279599   10.279599   10.279599   10.279646   10.279646  ]\n",
      " [ 0.03484416  0.03484416  0.03484416  0.03484416  0.03489269  0.03489269]\n",
      " [ 0.07397696  0.07397696  0.07397696  0.07397696  0.0740256   0.0740256 ]]\n",
      "Step: 88000,   Loss: 912.2240\n",
      "[[10.279562   10.279562   10.279562   10.279562   10.27958    10.27958   ]\n",
      " [ 0.03480768  0.03480768  0.03480768  0.03480768  0.03482544  0.03482544]\n",
      " [ 0.07394147  0.07394147  0.07394147  0.07394147  0.07395951  0.07395951]]\n",
      "Step: 89000,   Loss: 912.2198\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279614   10.279614  ]\n",
      " [ 0.03485363  0.03485363  0.03485363  0.03485363  0.03485883  0.03485883]\n",
      " [ 0.07398699  0.07398699  0.07398699  0.07398699  0.07399236  0.07399236]]\n",
      "Step: 90000,   Loss: 912.2233\n",
      "[[10.279546   10.279546   10.279546   10.279546   10.279534   10.279534  ]\n",
      " [ 0.03479206  0.03479206  0.03479206  0.03479206  0.03478065  0.03478065]\n",
      " [ 0.07392556  0.07392556  0.07392556  0.07392556  0.0739132   0.0739132 ]]\n",
      "Step: 91000,   Loss: 912.2190\n",
      "[[10.279622   10.279622   10.279622   10.279622   10.27962    10.27962   ]\n",
      " [ 0.03486812  0.03486812  0.03486812  0.03486812  0.03486644  0.03486644]\n",
      " [ 0.07400092  0.07400092  0.07400092  0.07400092  0.07399902  0.07399902]]\n",
      "Step: 92000,   Loss: 912.2247\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279608   10.279608  ]\n",
      " [ 0.03485438  0.03485438  0.03485438  0.03485438  0.03485317  0.03485317]\n",
      " [ 0.07398732  0.07398732  0.07398732  0.07398732  0.07398666  0.07398666]]\n",
      "Step: 93000,   Loss: 912.2259\n",
      "[[10.279623   10.279623   10.279623   10.279623   10.27955    10.27955   ]\n",
      " [ 0.03486899  0.03486899  0.03486899  0.03486899  0.03479336  0.03479336]\n",
      " [ 0.07400071  0.07400071  0.07400071  0.07400071  0.07392608  0.07392608]]\n",
      "Step: 94000,   Loss: 912.2247\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279611   10.279611  ]\n",
      " [ 0.03485608  0.03485608  0.03485608  0.03485608  0.03485764  0.03485764]\n",
      " [ 0.07398918  0.07398918  0.07398918  0.07398918  0.07399104  0.07399104]]\n",
      "Step: 95000,   Loss: 912.2235\n",
      "[[10.279579   10.279579   10.279579   10.279579   10.279613   10.279613  ]\n",
      " [ 0.03482464  0.03482464  0.03482464  0.03482464  0.03485827  0.03485827]\n",
      " [ 0.07395768  0.07395768  0.07395768  0.07395768  0.07399008  0.07399008]]\n",
      "Step: 96000,   Loss: 912.2226\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279607   10.279607  ]\n",
      " [ 0.03485348  0.03485348  0.03485348  0.03485348  0.03485162  0.03485162]\n",
      " [ 0.07398618  0.07398618  0.07398618  0.07398618  0.07398435  0.07398435]]\n",
      "Step: 97000,   Loss: 912.2253\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279616   10.279616  ]\n",
      " [ 0.03485657  0.03485657  0.03485657  0.03485657  0.03486282  0.03486282]\n",
      " [ 0.07398944  0.07398944  0.07398944  0.07398944  0.07399584  0.07399584]]\n",
      "Step: 98000,   Loss: 912.2227\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.27961    10.27961   ]\n",
      " [ 0.0348513   0.0348513   0.0348513   0.0348513   0.03485523  0.03485523]\n",
      " [ 0.0739847   0.0739847   0.0739847   0.0739847   0.0739885   0.0739885 ]]\n",
      "Step: 99000,   Loss: 912.2184\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.27961    10.27961   ]\n",
      " [ 0.0348514   0.0348514   0.0348514   0.0348514   0.0348542   0.0348542 ]\n",
      " [ 0.07398414  0.07398414  0.07398414  0.07398414  0.07398761  0.07398761]]\n",
      "Step: 100000,   Loss: 912.2211\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279603   10.279603  ]\n",
      " [ 0.03485425  0.03485425  0.03485425  0.03485425  0.03484731  0.03484731]\n",
      " [ 0.0739874   0.0739874   0.0739874   0.0739874   0.07398024  0.07398024]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 101000,   Loss: 912.2192\n",
      "[[10.279579   10.279579   10.279579   10.279579   10.279645   10.279645  ]\n",
      " [ 0.03482397  0.03482397  0.03482397  0.03482397  0.03489232  0.03489232]\n",
      " [ 0.07395722  0.07395722  0.07395722  0.07395722  0.07402467  0.07402467]]\n",
      "Step: 102000,   Loss: 912.2203\n",
      "[[10.279593   10.279593   10.279593   10.279593   10.279606   10.279606  ]\n",
      " [ 0.03483742  0.03483742  0.03483742  0.03483742  0.03484993  0.03484993]\n",
      " [ 0.07396982  0.07396982  0.07396982  0.07396982  0.0739826   0.0739826 ]]\n",
      "Step: 103000,   Loss: 912.2196\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279601   10.279601  ]\n",
      " [ 0.03485534  0.03485534  0.03485534  0.03485534  0.0348483   0.0348483 ]\n",
      " [ 0.07398838  0.07398838  0.07398838  0.07398838  0.07398137  0.07398137]]\n",
      "Step: 104000,   Loss: 912.2180\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279605   10.279605  ]\n",
      " [ 0.03485471  0.03485471  0.03485471  0.03485471  0.03485027  0.03485027]\n",
      " [ 0.07398785  0.07398785  0.07398785  0.07398785  0.07398466  0.07398466]]\n",
      "Step: 105000,   Loss: 912.2222\n",
      "[[10.2796135  10.2796135  10.2796135  10.2796135  10.279588   10.279588  ]\n",
      " [ 0.0348584   0.0348584   0.0348584   0.0348584   0.03483259  0.03483259]\n",
      " [ 0.07399149  0.07399149  0.07399149  0.07399149  0.0739648   0.0739648 ]]\n",
      "Step: 106000,   Loss: 912.2235\n",
      "[[10.279612   10.279612   10.279612   10.279612   10.279613   10.279613  ]\n",
      " [ 0.03485681  0.03485681  0.03485681  0.03485681  0.0348591   0.0348591 ]\n",
      " [ 0.07398951  0.07398951  0.07398951  0.07398951  0.07399116  0.07399116]]\n",
      "Step: 107000,   Loss: 912.2183\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279653   10.279653  ]\n",
      " [ 0.03485313  0.03485313  0.03485313  0.03485313  0.03489731  0.03489731]\n",
      " [ 0.07398542  0.07398542  0.07398542  0.07398542  0.07402965  0.07402965]]\n",
      "Step: 108000,   Loss: 912.2263\n",
      "[[10.279678   10.279678   10.279678   10.279678   10.27962    10.27962   ]\n",
      " [ 0.0349217   0.0349217   0.0349217   0.0349217   0.03486507  0.03486507]\n",
      " [ 0.07405556  0.07405556  0.07405556  0.07405556  0.07399859  0.07399859]]\n",
      "Step: 109000,   Loss: 912.2195\n",
      "[[10.279669   10.279669   10.279669   10.279669   10.279616   10.279616  ]\n",
      " [ 0.03491351  0.03491351  0.03491351  0.03491351  0.03486083  0.03486083]\n",
      " [ 0.07404739  0.07404739  0.07404739  0.07404739  0.07399482  0.07399482]]\n",
      "Step: 110000,   Loss: 912.2219\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279594   10.279594  ]\n",
      " [ 0.03485514  0.03485514  0.03485514  0.03485514  0.03483909  0.03483909]\n",
      " [ 0.07398748  0.07398748  0.07398748  0.07398748  0.07397109  0.07397109]]\n",
      "Step: 111000,   Loss: 912.2255\n",
      "[[10.279595   10.279595   10.279595   10.279595   10.279602   10.279602  ]\n",
      " [ 0.03483976  0.03483976  0.03483976  0.03483976  0.03484729  0.03484729]\n",
      " [ 0.07397262  0.07397262  0.07397262  0.07397262  0.07397982  0.07397982]]\n",
      "Step: 112000,   Loss: 912.2209\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.2795925  10.2795925 ]\n",
      " [ 0.03485037  0.03485037  0.03485037  0.03485037  0.03483715  0.03483715]\n",
      " [ 0.07398359  0.07398359  0.07398359  0.07398359  0.07397015  0.07397015]]\n",
      "Step: 113000,   Loss: 912.2249\n",
      "[[10.279656   10.279656   10.279656   10.279656   10.27966    10.27966   ]\n",
      " [ 0.03490078  0.03490078  0.03490078  0.03490078  0.03490419  0.03490419]\n",
      " [ 0.07403289  0.07403289  0.07403289  0.07403289  0.07403643  0.07403643]]\n",
      "Step: 114000,   Loss: 912.2258\n",
      "[[10.279538   10.279538   10.279538   10.279538   10.279605   10.279605  ]\n",
      " [ 0.03478337  0.03478337  0.03478337  0.03478337  0.03485251  0.03485251]\n",
      " [ 0.07391685  0.07391685  0.07391685  0.07391685  0.07398565  0.07398565]]\n",
      "Step: 115000,   Loss: 912.2213\n",
      "[[10.279562   10.279562   10.279562   10.279562   10.279618   10.279618  ]\n",
      " [ 0.03480729  0.03480729  0.03480729  0.03480729  0.0348624   0.0348624 ]\n",
      " [ 0.07394     0.07394     0.07394     0.07394     0.07399587  0.07399587]]\n",
      "Step: 116000,   Loss: 912.2225\n",
      "[[10.279546   10.279546   10.279546   10.279546   10.279531   10.279531  ]\n",
      " [ 0.03479088  0.03479088  0.03479088  0.03479088  0.03477576  0.03477576]\n",
      " [ 0.0739233   0.0739233   0.0739233   0.0739233   0.07390893  0.07390893]]\n",
      "Step: 117000,   Loss: 912.2238\n",
      "[[10.279594   10.279594   10.279594   10.279594   10.2796335  10.2796335 ]\n",
      " [ 0.03483939  0.03483939  0.03483939  0.03483939  0.03487839  0.03487839]\n",
      " [ 0.07397235  0.07397235  0.07397235  0.07397235  0.07401142  0.07401142]]\n",
      "Step: 118000,   Loss: 912.2241\n",
      "[[10.279612   10.279612   10.279612   10.279612   10.279603   10.279603  ]\n",
      " [ 0.03485728  0.03485728  0.03485728  0.03485728  0.03484767  0.03484767]\n",
      " [ 0.07398959  0.07398959  0.07398959  0.07398959  0.07398032  0.07398032]]\n",
      "Step: 119000,   Loss: 912.2225\n",
      "[[10.279614   10.279614   10.279614   10.279614   10.27961    10.27961   ]\n",
      " [ 0.03485785  0.03485785  0.03485785  0.03485785  0.03485502  0.03485502]\n",
      " [ 0.07399166  0.07399166  0.07399166  0.07399166  0.07398863  0.07398863]]\n",
      "Step: 120000,   Loss: 912.2230\n",
      "[[10.279665   10.279665   10.279665   10.279665   10.279627   10.279627  ]\n",
      " [ 0.03491093  0.03491093  0.03491093  0.03491093  0.03487226  0.03487226]\n",
      " [ 0.07404365  0.07404365  0.07404365  0.07404365  0.07400532  0.07400532]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(120001):\n",
    "    if step % 1000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "        print(w_val)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "[[6.3351717 6.3351717 6.3351717 6.3351717 6.3351717 6.3351717]\n",
      " [1.522709  1.522709  1.522709  1.522709  1.522709  1.522709 ]\n",
      " [1.482626  1.482626  1.482626  1.482626  1.482626  1.482626 ]]\n",
      "Step: 20000,   Loss: 1298.2266\n",
      "[[10.160319   10.160319   10.160319   10.160319   10.160319   10.160319  ]\n",
      " [-0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206]\n",
      " [ 0.0855459   0.0855459   0.0855459   0.0855459   0.0855459   0.0855459 ]]\n",
      "Step: 30000,   Loss: 914.2769\n",
      "[[10.271035   10.271035   10.271035   10.271035   10.271035   10.271035  ]\n",
      " [ 0.03055731  0.03055731  0.03055731  0.03055731  0.03055731  0.03055731]\n",
      " [ 0.07483479  0.07483479  0.07483479  0.07483479  0.07483479  0.07483479]]\n",
      "Step: 40000,   Loss: 912.2196\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279606   10.279606  ]\n",
      " [ 0.03485141  0.03485141  0.03485141  0.03485141  0.03485141  0.03485141]\n",
      " [ 0.07398419  0.07398419  0.07398419  0.07398419  0.07398419  0.07398419]]\n",
      "Step: 50000,   Loss: 912.2220\n",
      "[[10.279614   10.279614   10.279614   10.279614   10.279593   10.279593  ]\n",
      " [ 0.0348593   0.0348593   0.0348593   0.0348593   0.03483845  0.03483845]\n",
      " [ 0.07399281  0.07399281  0.07399281  0.07399281  0.07397114  0.07397114]]\n",
      "Step: 60000,   Loss: 912.2256\n",
      "[[10.279628   10.279628   10.279628   10.279628   10.2796135  10.2796135 ]\n",
      " [ 0.0348731   0.0348731   0.0348731   0.0348731   0.0348588   0.0348588 ]\n",
      " [ 0.07400642  0.07400642  0.07400642  0.07400642  0.07399222  0.07399222]]\n",
      "Step: 70000,   Loss: 912.2224\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279614   10.279614  ]\n",
      " [ 0.03485594  0.03485594  0.03485594  0.03485594  0.03485974  0.03485974]\n",
      " [ 0.07398903  0.07398903  0.07398903  0.07398903  0.07399241  0.07399241]]\n",
      "Step: 80000,   Loss: 912.2250\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279569   10.279569  ]\n",
      " [ 0.03485684  0.03485684  0.03485684  0.03485684  0.03481402  0.03481402]\n",
      " [ 0.07398963  0.07398963  0.07398963  0.07398963  0.07394752  0.07394752]]\n",
      "Step: 90000,   Loss: 912.2233\n",
      "[[10.279546   10.279546   10.279546   10.279546   10.279534   10.279534  ]\n",
      " [ 0.03479206  0.03479206  0.03479206  0.03479206  0.03478065  0.03478065]\n",
      " [ 0.07392556  0.07392556  0.07392556  0.07392556  0.0739132   0.0739132 ]]\n",
      "Step: 100000,   Loss: 912.2211\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279603   10.279603  ]\n",
      " [ 0.03485425  0.03485425  0.03485425  0.03485425  0.03484731  0.03484731]\n",
      " [ 0.0739874   0.0739874   0.0739874   0.0739874   0.07398024  0.07398024]]\n",
      "Step: 110000,   Loss: 912.2219\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279594   10.279594  ]\n",
      " [ 0.03485514  0.03485514  0.03485514  0.03485514  0.03483909  0.03483909]\n",
      " [ 0.07398748  0.07398748  0.07398748  0.07398748  0.07397109  0.07397109]]\n",
      "Step: 120000,   Loss: 912.2230\n",
      "[[10.279665   10.279665   10.279665   10.279665   10.279627   10.279627  ]\n",
      " [ 0.03491093  0.03491093  0.03491093  0.03491093  0.03487226  0.03487226]\n",
      " [ 0.07404365  0.07404365  0.07404365  0.07404365  0.07400532  0.07400532]]\n",
      "Step: 130000,   Loss: 912.2262\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279617   10.279617  ]\n",
      " [ 0.03485667  0.03485667  0.03485667  0.03485667  0.03486151  0.03486151]\n",
      " [ 0.07399017  0.07399017  0.07399017  0.07399017  0.0739946   0.0739946 ]]\n",
      "Step: 140000,   Loss: 912.2234\n",
      "[[10.279621   10.279621   10.279621   10.279621   10.279615   10.279615  ]\n",
      " [ 0.0348654   0.0348654   0.0348654   0.0348654   0.03485952  0.03485952]\n",
      " [ 0.07399818  0.07399818  0.07399818  0.07399818  0.07399206  0.07399206]]\n",
      "Step: 150000,   Loss: 912.2238\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279607   10.279607  ]\n",
      " [ 0.03485673  0.03485673  0.03485673  0.03485673  0.03485176  0.03485176]\n",
      " [ 0.07399029  0.07399029  0.07399029  0.07399029  0.07398561  0.07398561]]\n",
      "Step: 160000,   Loss: 912.2209\n",
      "[[10.279621   10.279621   10.279621   10.279621   10.279612   10.279612  ]\n",
      " [ 0.03486743  0.03486743  0.03486743  0.03486743  0.03485543  0.03485543]\n",
      " [ 0.07400013  0.07400013  0.07400013  0.07400013  0.07398807  0.07398807]]\n",
      "Step: 170000,   Loss: 912.2215\n",
      "[[10.279592   10.279592   10.279592   10.279592   10.279597   10.279597  ]\n",
      " [ 0.03483761  0.03483761  0.03483761  0.03483761  0.03484295  0.03484295]\n",
      " [ 0.07397009  0.07397009  0.07397009  0.07397009  0.07397576  0.07397576]]\n",
      "Step: 180000,   Loss: 912.2236\n",
      "[[10.279596   10.279596   10.279596   10.279596   10.279598   10.279598  ]\n",
      " [ 0.03484053  0.03484053  0.03484053  0.03484053  0.0348443   0.0348443 ]\n",
      " [ 0.07397375  0.07397375  0.07397375  0.07397375  0.07397719  0.07397719]]\n",
      "Step: 190000,   Loss: 912.2234\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279595   10.279595  ]\n",
      " [ 0.03485306  0.03485306  0.03485306  0.03485306  0.03484043  0.03484043]\n",
      " [ 0.0739859   0.0739859   0.0739859   0.0739859   0.07397205  0.07397205]]\n",
      "Step: 200000,   Loss: 912.2258\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279625   10.279625  ]\n",
      " [ 0.03485567  0.03485567  0.03485567  0.03485567  0.03486922  0.03486922]\n",
      " [ 0.07398859  0.07398859  0.07398859  0.07398859  0.07400244  0.07400244]]\n",
      "Step: 210000,   Loss: 912.2233\n",
      "[[10.279618   10.279618   10.279618   10.279618   10.279629   10.279629  ]\n",
      " [ 0.0348631   0.0348631   0.0348631   0.0348631   0.03487322  0.03487322]\n",
      " [ 0.07399644  0.07399644  0.07399644  0.07399644  0.07400681  0.07400681]]\n",
      "Step: 220000,   Loss: 912.2211\n",
      "[[10.2795925  10.2795925  10.2795925  10.2795925  10.279602   10.279602  ]\n",
      " [ 0.03483687  0.03483687  0.03483687  0.03483687  0.03484676  0.03484676]\n",
      " [ 0.07397014  0.07397014  0.07397014  0.07397014  0.07397938  0.07397938]]\n",
      "Step: 230000,   Loss: 912.2211\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279612   10.279612  ]\n",
      " [ 0.03485458  0.03485458  0.03485458  0.03485458  0.03485664  0.03485664]\n",
      " [ 0.07398745  0.07398745  0.07398745  0.07398745  0.07398974  0.07398974]]\n",
      "Step: 240000,   Loss: 912.2196\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279607   10.279607  ]\n",
      " [ 0.03485065  0.03485065  0.03485065  0.03485065  0.03485167  0.03485167]\n",
      " [ 0.07398446  0.07398446  0.07398446  0.07398446  0.07398459  0.07398459]]\n",
      "Step: 250000,   Loss: 912.2282\n",
      "[[10.279564   10.279564   10.279564   10.279564   10.27959    10.27959   ]\n",
      " [ 0.03480914  0.03480914  0.03480914  0.03480914  0.03483398  0.03483398]\n",
      " [ 0.07394207  0.07394207  0.07394207  0.07394207  0.07396759  0.07396759]]\n",
      "Step: 260000,   Loss: 912.2219\n",
      "[[10.279599   10.279599   10.279599   10.279599   10.279617   10.279617  ]\n",
      " [ 0.03484401  0.03484401  0.03484401  0.03484401  0.03486292  0.03486292]\n",
      " [ 0.07397649  0.07397649  0.07397649  0.07397649  0.0739958   0.0739958 ]]\n",
      "Step: 270000,   Loss: 912.2199\n",
      "[[10.279605   10.279605   10.279605   10.279605   10.279607   10.279607  ]\n",
      " [ 0.03485079  0.03485079  0.03485079  0.03485079  0.03485095  0.03485095]\n",
      " [ 0.07398351  0.07398351  0.07398351  0.07398351  0.07398406  0.07398406]]\n",
      "Step: 280000,   Loss: 912.2256\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279609   10.279609  ]\n",
      " [ 0.03485673  0.03485673  0.03485673  0.03485673  0.03485347  0.03485347]\n",
      " [ 0.07398963  0.07398963  0.07398963  0.07398963  0.07398731  0.07398731]]\n",
      "Step: 290000,   Loss: 912.2209\n",
      "[[10.279588   10.279588   10.279588   10.279588   10.279635   10.279635  ]\n",
      " [ 0.03483288  0.03483288  0.03483288  0.03483288  0.03487987  0.03487987]\n",
      " [ 0.0739659   0.0739659   0.0739659   0.0739659   0.07401311  0.07401311]]\n",
      "Step: 300000,   Loss: 912.2250\n",
      "[[10.2796135  10.2796135  10.2796135  10.2796135  10.279609   10.279609  ]\n",
      " [ 0.03485925  0.03485925  0.03485925  0.03485925  0.0348547   0.0348547 ]\n",
      " [ 0.07399197  0.07399197  0.07399197  0.07399197  0.07398758  0.07398758]]\n",
      "Step: 310000,   Loss: 912.2236\n",
      "[[10.279621   10.279621   10.279621   10.279621   10.279589   10.279589  ]\n",
      " [ 0.0348677   0.0348677   0.0348677   0.0348677   0.03483238  0.03483238]\n",
      " [ 0.07400057  0.07400057  0.07400057  0.07400057  0.07396599  0.07396599]]\n",
      "Step: 320000,   Loss: 912.2239\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279615   10.279615  ]\n",
      " [ 0.03485223  0.03485223  0.03485223  0.03485223  0.0348602   0.0348602 ]\n",
      " [ 0.07398472  0.07398472  0.07398472  0.07398472  0.07399343  0.07399343]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 330000,   Loss: 912.2200\n",
      "[[10.279624   10.279624   10.279624   10.279624   10.279575   10.279575  ]\n",
      " [ 0.03487044  0.03487044  0.03487044  0.03487044  0.03482227  0.03482227]\n",
      " [ 0.07400241  0.07400241  0.07400241  0.07400241  0.07395405  0.07395405]]\n",
      "Step: 340000,   Loss: 912.2253\n",
      "[[10.279615   10.279615   10.279615   10.279615   10.279626   10.279626  ]\n",
      " [ 0.0348608   0.0348608   0.0348608   0.0348608   0.0348715   0.0348715 ]\n",
      " [ 0.07399474  0.07399474  0.07399474  0.07399474  0.0740047   0.0740047 ]]\n",
      "Step: 350000,   Loss: 912.2246\n",
      "[[10.279617   10.279617   10.279617   10.279617   10.279613   10.279613  ]\n",
      " [ 0.03486301  0.03486301  0.03486301  0.03486301  0.03485679  0.03485679]\n",
      " [ 0.07399604  0.07399604  0.07399604  0.07399604  0.07398956  0.07398956]]\n",
      "Step: 360000,   Loss: 912.2256\n",
      "[[10.27957    10.27957    10.27957    10.27957    10.279554   10.279554  ]\n",
      " [ 0.0348159   0.0348159   0.0348159   0.0348159   0.03479875  0.03479875]\n",
      " [ 0.07394832  0.07394832  0.07394832  0.07394832  0.07393143  0.07393143]]\n",
      "Step: 370000,   Loss: 912.2162\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.27964    10.27964   ]\n",
      " [ 0.03485249  0.03485249  0.03485249  0.03485249  0.03488619  0.03488619]\n",
      " [ 0.07398521  0.07398521  0.07398521  0.07398521  0.07401942  0.07401942]]\n",
      "Step: 380000,   Loss: 912.2211\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279606   10.279606  ]\n",
      " [ 0.03485266  0.03485266  0.03485266  0.03485266  0.0348506   0.0348506 ]\n",
      " [ 0.07398565  0.07398565  0.07398565  0.07398565  0.07398389  0.07398389]]\n",
      "Step: 390000,   Loss: 912.2223\n",
      "[[10.279596   10.279596   10.279596   10.279596   10.279608   10.279608  ]\n",
      " [ 0.03484161  0.03484161  0.03484161  0.03484161  0.03485278  0.03485278]\n",
      " [ 0.0739743   0.0739743   0.0739743   0.0739743   0.07398579  0.07398579]]\n",
      "Step: 400000,   Loss: 912.2241\n",
      "[[10.279658   10.279658   10.279658   10.279658   10.279637   10.279637  ]\n",
      " [ 0.03490319  0.03490319  0.03490319  0.03490319  0.03488405  0.03488405]\n",
      " [ 0.0740363   0.0740363   0.0740363   0.0740363   0.07401785  0.07401785]]\n",
      "Step: 410000,   Loss: 912.2237\n",
      "[[10.279615   10.279615   10.279615   10.279615   10.2796     10.2796    ]\n",
      " [ 0.03486026  0.03486026  0.03486026  0.03486026  0.03484594  0.03484594]\n",
      " [ 0.07399212  0.07399212  0.07399212  0.07399212  0.07397902  0.07397902]]\n",
      "Step: 420000,   Loss: 912.2174\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279619   10.279619  ]\n",
      " [ 0.0348538   0.0348538   0.0348538   0.0348538   0.03486292  0.03486292]\n",
      " [ 0.07398636  0.07398636  0.07398636  0.07398636  0.07399568  0.07399568]]\n",
      "Step: 430000,   Loss: 912.2241\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279588   10.279588  ]\n",
      " [ 0.03485792  0.03485792  0.03485792  0.03485792  0.03483258  0.03483258]\n",
      " [ 0.07399062  0.07399062  0.07399062  0.07399062  0.07396491  0.07396491]]\n",
      "Step: 440000,   Loss: 912.2189\n",
      "[[10.279553   10.279553   10.279553   10.279553   10.279596   10.279596  ]\n",
      " [ 0.03479875  0.03479875  0.03479875  0.03479875  0.03484104  0.03484104]\n",
      " [ 0.07393137  0.07393137  0.07393137  0.07393137  0.07397407  0.07397407]]\n",
      "Step: 450000,   Loss: 912.2191\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279597   10.279597  ]\n",
      " [ 0.03485189  0.03485189  0.03485189  0.03485189  0.03484163  0.03484163]\n",
      " [ 0.07398521  0.07398521  0.07398521  0.07398521  0.0739754   0.0739754 ]]\n",
      "Step: 460000,   Loss: 912.2203\n",
      "[[10.279604   10.279604   10.279604   10.279604   10.279617   10.279617  ]\n",
      " [ 0.03484933  0.03484933  0.03484933  0.03484933  0.03486079  0.03486079]\n",
      " [ 0.07398277  0.07398277  0.07398277  0.07398277  0.07399409  0.07399409]]\n",
      "Step: 470000,   Loss: 912.2220\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279619   10.279619  ]\n",
      " [ 0.03485231  0.03485231  0.03485231  0.03485231  0.03486465  0.03486465]\n",
      " [ 0.07398465  0.07398465  0.07398465  0.07398465  0.0739973   0.0739973 ]]\n",
      "Step: 480000,   Loss: 912.2239\n",
      "[[10.2796     10.2796     10.2796     10.2796     10.279618   10.279618  ]\n",
      " [ 0.03484444  0.03484444  0.03484444  0.03484444  0.03486283  0.03486283]\n",
      " [ 0.07397745  0.07397745  0.07397745  0.07397745  0.07399528  0.07399528]]\n",
      "Step: 490000,   Loss: 912.2260\n",
      "[[10.279599   10.279599   10.279599   10.279599   10.279624   10.279624  ]\n",
      " [ 0.03484671  0.03484671  0.03484671  0.03484671  0.0348699   0.0348699 ]\n",
      " [ 0.07397854  0.07397854  0.07397854  0.07397854  0.07400329  0.07400329]]\n",
      "Step: 500000,   Loss: 912.2245\n",
      "[[10.27964    10.27964    10.27964    10.27964    10.279622   10.279622  ]\n",
      " [ 0.03488478  0.03488478  0.03488478  0.03488478  0.03486747  0.03486747]\n",
      " [ 0.07401897  0.07401897  0.07401897  0.07401897  0.07400138  0.07400138]]\n",
      "Step: 510000,   Loss: 912.2257\n",
      "[[10.279598   10.279598   10.279598   10.279598   10.2796135  10.2796135 ]\n",
      " [ 0.03484382  0.03484382  0.03484382  0.03484382  0.03485901  0.03485901]\n",
      " [ 0.07397686  0.07397686  0.07397686  0.07397686  0.07399129  0.07399129]]\n",
      "Step: 520000,   Loss: 912.2183\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279597   10.279597  ]\n",
      " [ 0.03485149  0.03485149  0.03485149  0.03485149  0.03484224  0.03484224]\n",
      " [ 0.07398537  0.07398537  0.07398537  0.07398537  0.07397535  0.07397535]]\n",
      "Step: 530000,   Loss: 912.2245\n",
      "[[10.279599   10.279599   10.279599   10.279599   10.279608   10.279608  ]\n",
      " [ 0.03484574  0.03484574  0.03484574  0.03484574  0.03485328  0.03485328]\n",
      " [ 0.07397811  0.07397811  0.07397811  0.07397811  0.0739866   0.0739866 ]]\n",
      "Step: 540000,   Loss: 912.2178\n",
      "[[10.279608   10.279608   10.279608   10.279608   10.279607   10.279607  ]\n",
      " [ 0.03485352  0.03485352  0.03485352  0.03485352  0.03485335  0.03485335]\n",
      " [ 0.07398625  0.07398625  0.07398625  0.07398625  0.07398632  0.07398632]]\n",
      "Step: 550000,   Loss: 912.2202\n",
      "[[10.279578   10.279578   10.279578   10.279578   10.279633   10.279633  ]\n",
      " [ 0.0348242   0.0348242   0.0348242   0.0348242   0.03487709  0.03487709]\n",
      " [ 0.07395675  0.07395675  0.07395675  0.07395675  0.0740098   0.0740098 ]]\n",
      "Step: 560000,   Loss: 912.2217\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279616   10.279616  ]\n",
      " [ 0.0348508   0.0348508   0.0348508   0.0348508   0.03485993  0.03485993]\n",
      " [ 0.0739842   0.0739842   0.0739842   0.0739842   0.07399337  0.07399337]]\n",
      "Step: 570000,   Loss: 912.2190\n",
      "[[10.27964    10.27964    10.27964    10.27964    10.279637   10.279637  ]\n",
      " [ 0.03488407  0.03488407  0.03488407  0.03488407  0.0348817   0.0348817 ]\n",
      " [ 0.07401725  0.07401725  0.07401725  0.07401725  0.07401408  0.07401408]]\n",
      "Step: 580000,   Loss: 912.2178\n",
      "[[10.279607   10.279607   10.279607   10.279607   10.279649   10.279649  ]\n",
      " [ 0.03485191  0.03485191  0.03485191  0.03485191  0.03489503  0.03489503]\n",
      " [ 0.07398516  0.07398516  0.07398516  0.07398516  0.07402799  0.07402799]]\n",
      "Step: 590000,   Loss: 912.2269\n",
      "[[10.279502   10.279502   10.279502   10.279502   10.279504   10.279504  ]\n",
      " [ 0.03474647  0.03474647  0.03474647  0.03474647  0.03474897  0.03474897]\n",
      " [ 0.07387737  0.07387737  0.07387737  0.07387737  0.07388081  0.07388081]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-7007c6bea5fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mw_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(1200001):\n",
    "    if step % 10000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "        print(w_val)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "[0.]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "[5.046035]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 20000,   Loss: 1298.2266\n",
      "[1.7169173]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 30000,   Loss: 914.2769\n",
      "[-6.064686]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 40000,   Loss: 912.2196\n",
      "[-6.6760926]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 50000,   Loss: 912.2220\n",
      "[-6.6760907]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 60000,   Loss: 912.2256\n",
      "[-6.6760716]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 70000,   Loss: 912.2224\n",
      "[-6.676084]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 80000,   Loss: 912.2250\n",
      "[-6.6761017]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 90000,   Loss: 912.2233\n",
      "[-6.6761675]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n",
      "Step: 100000,   Loss: 912.2211\n",
      "[-6.67609]\n",
      "<tf.Variable 'bias_21:0' shape=(1,) dtype=float32_ref>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-62cf1c70cc06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(120001):\n",
    "    if step % 10000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "        w_val = sess.run(b)\n",
    "        print(w_val)\n",
    "        print(b)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 000,   Loss: 5899074.0000\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "[0.]\n",
      "Step: 10000,   Loss: 93395.4453\n",
      "[[6.3351717 6.3351717 6.3351717 6.3351717 6.3351717 6.3351717]\n",
      " [1.522709  1.522709  1.522709  1.522709  1.522709  1.522709 ]\n",
      " [1.482626  1.482626  1.482626  1.482626  1.482626  1.482626 ]]\n",
      "[5.046035]\n",
      "Step: 20000,   Loss: 1298.2266\n",
      "[[10.160319   10.160319   10.160319   10.160319   10.160319   10.160319  ]\n",
      " [-0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206 -0.02420206]\n",
      " [ 0.0855459   0.0855459   0.0855459   0.0855459   0.0855459   0.0855459 ]]\n",
      "[1.7169173]\n",
      "Step: 30000,   Loss: 914.2769\n",
      "[[10.271035   10.271035   10.271035   10.271035   10.271035   10.271035  ]\n",
      " [ 0.03055731  0.03055731  0.03055731  0.03055731  0.03055731  0.03055731]\n",
      " [ 0.07483479  0.07483479  0.07483479  0.07483479  0.07483479  0.07483479]]\n",
      "[-6.064686]\n",
      "Step: 40000,   Loss: 912.2196\n",
      "[[10.279606   10.279606   10.279606   10.279606   10.279606   10.279606  ]\n",
      " [ 0.03485141  0.03485141  0.03485141  0.03485141  0.03485141  0.03485141]\n",
      " [ 0.07398419  0.07398419  0.07398419  0.07398419  0.07398419  0.07398419]]\n",
      "[-6.6760926]\n",
      "Step: 50000,   Loss: 912.2220\n",
      "[[10.279614   10.279614   10.279614   10.279614   10.279593   10.279593  ]\n",
      " [ 0.0348593   0.0348593   0.0348593   0.0348593   0.03483845  0.03483845]\n",
      " [ 0.07399281  0.07399281  0.07399281  0.07399281  0.07397114  0.07397114]]\n",
      "[-6.6760907]\n",
      "Step: 60000,   Loss: 912.2256\n",
      "[[10.279628   10.279628   10.279628   10.279628   10.2796135  10.2796135 ]\n",
      " [ 0.0348731   0.0348731   0.0348731   0.0348731   0.0348588   0.0348588 ]\n",
      " [ 0.07400642  0.07400642  0.07400642  0.07400642  0.07399222  0.07399222]]\n",
      "[-6.6760716]\n",
      "Step: 70000,   Loss: 912.2224\n",
      "[[10.279611   10.279611   10.279611   10.279611   10.279614   10.279614  ]\n",
      " [ 0.03485594  0.03485594  0.03485594  0.03485594  0.03485974  0.03485974]\n",
      " [ 0.07398903  0.07398903  0.07398903  0.07398903  0.07399241  0.07399241]]\n",
      "[-6.676084]\n",
      "Step: 80000,   Loss: 912.2250\n",
      "[[10.279613   10.279613   10.279613   10.279613   10.279569   10.279569  ]\n",
      " [ 0.03485684  0.03485684  0.03485684  0.03485684  0.03481402  0.03481402]\n",
      " [ 0.07398963  0.07398963  0.07398963  0.07398963  0.07394752  0.07394752]]\n",
      "[-6.6761017]\n",
      "Step: 90000,   Loss: 912.2233\n",
      "[[10.279546   10.279546   10.279546   10.279546   10.279534   10.279534  ]\n",
      " [ 0.03479206  0.03479206  0.03479206  0.03479206  0.03478065  0.03478065]\n",
      " [ 0.07392556  0.07392556  0.07392556  0.07392556  0.0739132   0.0739132 ]]\n",
      "[-6.6761675]\n",
      "Step: 100000,   Loss: 912.2211\n",
      "[[10.27961    10.27961    10.27961    10.27961    10.279603   10.279603  ]\n",
      " [ 0.03485425  0.03485425  0.03485425  0.03485425  0.03484731  0.03484731]\n",
      " [ 0.0739874   0.0739874   0.0739874   0.0739874   0.07398024  0.07398024]]\n",
      "[-6.67609]\n",
      "Step: 110000,   Loss: 912.2219\n",
      "[[10.279609   10.279609   10.279609   10.279609   10.279594   10.279594  ]\n",
      " [ 0.03485514  0.03485514  0.03485514  0.03485514  0.03483909  0.03483909]\n",
      " [ 0.07398748  0.07398748  0.07398748  0.07398748  0.07397109  0.07397109]]\n",
      "[-6.676095]\n",
      "Step: 120000,   Loss: 912.2230\n",
      "[[10.279665   10.279665   10.279665   10.279665   10.279627   10.279627  ]\n",
      " [ 0.03491093  0.03491093  0.03491093  0.03491093  0.03487226  0.03487226]\n",
      " [ 0.07404365  0.07404365  0.07404365  0.07404365  0.07400532  0.07400532]]\n",
      "[-6.676037]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# matplotlib パッケージを読み込み\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # データを生成\n",
    "x_data = np.asarray([[10,20,30], [24,80,10], [30,40,9], [40,25,15], [51,80,70], [60,80,50]], dtype=np.float32)\n",
    "# #x_data = x_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける\n",
    "# # 物件の家賃\n",
    "y_data = np.asarray([[103], [242], [304], [402], [519], [625]])\n",
    "# #y_data = y_data * 0.01 # 結果がNaN(無限大)になるので、0.01掛ける#正規化\n",
    "\n",
    "n_1 = len(x_data)#6\n",
    "n_2 = len(x_data[0])#3\n",
    "\n",
    "# モデル\n",
    "#x_d = tf.placeholder(tf.float32, [None,n])\n",
    "#y_d = tf.placeholder(tf.float32, [None,1])\n",
    "w = tf.Variable(tf.zeros([n_2, n_1]))\n",
    "b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "y_hat = tf.add(tf.matmul(x_data, w), b)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "# \t# init 操作を実行します。\n",
    "# \tsess.run(init_op)\n",
    "# \tsess.run(y_hat)\n",
    "# \tprint(y_hat)\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "loss = tf.reduce_sum(tf.square(y_data - y_hat))\n",
    "\n",
    "# 確率的最急勾配法\n",
    "rate = 0.5\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 変数初期化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(120001):\n",
    "    if step % 10000 == 0:\n",
    "        loss_val = sess.run(loss) \n",
    "        print('Step: %03d,   Loss: %5.4f' % (step,loss_val))\n",
    "        w_val = sess.run(w)\n",
    "        b_val = sess.run(b)\n",
    "        print(w_val)\n",
    "        print(b_val)\n",
    "    sess.run(train)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m51\u001b[0m\n\u001b[1;33m    with tf.Session() as sess:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#ボストンデータ読み込み\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "#学習データ準備\n",
    "f_num = df.shape[1] - 1\n",
    "train_X = np.array(df.iloc[:, :f_num])\n",
    "train_Y = np.array(df.iloc[:, f_num: f_num + 1])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "#正規化\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_X)\n",
    "train_X = ss.transform(train_X)\n",
    "\n",
    "#プレースホルダー\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, name = \"Y\")\n",
    "\n",
    "#変数（パラメータ）\n",
    "with tf.name_scope('parameter'):\n",
    "    W = tf.Variable(tf.zeros([f_num, 1]), name = \"weight\")\n",
    "    b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "\n",
    "#モデル\n",
    "with tf.name_scope('model'):\n",
    "    pred = tf.add(tf.matmul(X, W), b) #matmulは行列の積\n",
    "\n",
    "#損失関数\n",
    "with tf.name_scope('loss'):\n",
    "    # Mean squared error\n",
    "    loss = tf.reduce_mean(tf.square(pred - Y))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#決定係数(R2)\n",
    "with tf.name_scope('r2'):\n",
    "    r2 = 1 - (tf.reduce_sum(tf.square(Y - pred)) / tf.reduce_sum(tf.square(Y - tf.reduce_mean(Y))))\n",
    "    tf.summary.scalar('r2', r2)\n",
    "\n",
    " with tf.Session() as sess:\n",
    "    # ログの設定\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"boston_log\", sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())#変数初期化\n",
    "    \n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i != 0 and i % 200 == 0: # 200ステップごとに精度を出力\n",
    "            train_summary, train_loss, train_r2 = sess.run([summary, loss, r2], feed_dict={X: train_X, Y:train_Y})# コストと精度を出力\n",
    "            writer.add_summary(train_summary, i) #summaryの更新\n",
    "            \n",
    "            print(\"Step:\", '%04d' % (i), \"loss=\", \"{:.9f}\".format(train_loss), \"r2=\", \"{:.9f}\".format(train_r2), \"W=\", sess.run(W), \"b=\", sess.run(b))            \n",
    "            \n",
    "    training_cost, training_r2 = sess.run([loss,r2], feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"Training r2=\", training_r2, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0200 loss= 23.045347214 r2= 0.727014184 W= [[-0.64401853]\n",
      " [ 0.5383606 ]\n",
      " [-0.40472373]\n",
      " [ 0.8027229 ]\n",
      " [-0.8915157 ]\n",
      " [ 3.2064683 ]\n",
      " [-0.15766497]\n",
      " [-1.9623485 ]\n",
      " [ 0.7835223 ]\n",
      " [-0.47531322]\n",
      " [-1.8151902 ]\n",
      " [ 0.8904133 ]\n",
      " [-3.3628335 ]] b= [22.144428]\n",
      "Step: 0400 loss= 22.291725159 r2= 0.735941231 W= [[-0.73864853]\n",
      " [ 0.7398913 ]\n",
      " [-0.31310534]\n",
      " [ 0.7517555 ]\n",
      " [-1.4155362 ]\n",
      " [ 2.9622095 ]\n",
      " [-0.1261122 ]\n",
      " [-2.5774574 ]\n",
      " [ 1.2765746 ]\n",
      " [-0.7487224 ]\n",
      " [-1.9217359 ]\n",
      " [ 0.88914   ]\n",
      " [-3.601969  ]] b= [22.525974]\n",
      "Step: 0600 loss= 22.087738037 r2= 0.738357604 W= [[-0.80169594]\n",
      " [ 0.8672558 ]\n",
      " [-0.23020206]\n",
      " [ 0.7359206 ]\n",
      " [-1.7025048 ]\n",
      " [ 2.8329444 ]\n",
      " [-0.08082211]\n",
      " [-2.859183  ]\n",
      " [ 1.6138077 ]\n",
      " [-1.0113053 ]\n",
      " [-1.9768058 ]\n",
      " [ 0.8702072 ]\n",
      " [-3.6752095 ]] b= [22.532682]\n",
      "Step: 0800 loss= 22.000528336 r2= 0.739390612 W= [[-0.84074306]\n",
      " [ 0.9409294 ]\n",
      " [-0.15539789]\n",
      " [ 0.7245094 ]\n",
      " [-1.8575783 ]\n",
      " [ 2.7686372 ]\n",
      " [-0.04816898]\n",
      " [-2.9927185 ]\n",
      " [ 1.8614947 ]\n",
      " [-1.2325811 ]\n",
      " [-2.007547  ]\n",
      " [ 0.86089647]\n",
      " [-3.7053533 ]] b= [22.53276]\n",
      "Training cost= 21.956875 Training r2= 0.73990774 W= [[-0.8650283 ]\n",
      " [ 0.9845838 ]\n",
      " [-0.09241167]\n",
      " [ 0.7154488 ]\n",
      " [-1.9416195 ]\n",
      " [ 2.7341459 ]\n",
      " [-0.02709522]\n",
      " [-3.0557144 ]\n",
      " [ 2.0462692 ]\n",
      " [-1.4119295 ]\n",
      " [-2.0259018 ]\n",
      " [ 0.85696864]\n",
      " [-3.72002   ]] b= [22.53276] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#ボストンデータ読み込み\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "#学習データ準備\n",
    "f_num = df.shape[1] - 1\n",
    "train_X = np.array(df.iloc[:, :f_num])\n",
    "train_Y = np.array(df.iloc[:, f_num: f_num + 1])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "#正規化\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_X)\n",
    "train_X = ss.transform(train_X)\n",
    "\n",
    "#プレースホルダー\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, name = \"Y\")\n",
    "\n",
    "#変数（パラメータ）\n",
    "with tf.name_scope('parameter'):\n",
    "    W = tf.Variable(tf.zeros([f_num, 1]), name = \"weight\")\n",
    "    b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "\n",
    "#モデル\n",
    "with tf.name_scope('model'):\n",
    "    pred = tf.add(tf.matmul(X, W), b) #matmulは行列の積\n",
    "\n",
    "#損失関数\n",
    "with tf.name_scope('loss'):\n",
    "    # Mean squared error\n",
    "    loss = tf.reduce_mean(tf.square(pred - Y))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#決定係数(R2)\n",
    "with tf.name_scope('r2'):\n",
    "    r2 = 1 - (tf.reduce_sum(tf.square(Y - pred)) / tf.reduce_sum(tf.square(Y - tf.reduce_mean(Y))))\n",
    "    tf.summary.scalar('r2', r2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # ログの設定\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"boston_log\", sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())#変数初期化\n",
    "    \n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i != 0 and i % 200 == 0: # 200ステップごとに精度を出力\n",
    "            train_summary, train_loss, train_r2 = sess.run([summary, loss, r2], feed_dict={X: train_X, Y:train_Y})# コストと精度を出力\n",
    "            writer.add_summary(train_summary, i) #summaryの更新\n",
    "            \n",
    "            print(\"Step:\", '%04d' % (i), \"loss=\", \"{:.9f}\".format(train_loss), \"r2=\", \"{:.9f}\".format(train_r2), \"W=\", sess.run(W), \"b=\", sess.run(b))            \n",
    "            \n",
    "    training_cost, training_r2 = sess.run([loss,r2], feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"Training r2=\", training_r2, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'data/X', defined at:\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-5fa4b71e6af0>\", line 25, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-36a603dc361f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 200ステップごとに精度を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mtrain_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# コストと精度を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#summaryの更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'data/X', defined at:\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-5fa4b71e6af0>\", line 25, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#ボストンデータ読み込み\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "#学習データ準備\n",
    "f_num = df.shape[1] - 1\n",
    "train_X = np.array(df.iloc[:, :f_num])\n",
    "train_Y = np.array(df.iloc[:, f_num: f_num + 1])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "#正規化\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_X)\n",
    "train_X = ss.transform(train_X)\n",
    "\n",
    "#プレースホルダー\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, name = \"Y\")\n",
    "\n",
    "#変数（パラメータ）\n",
    "with tf.name_scope('parameter'):\n",
    "    W = tf.Variable(tf.zeros([f_num, 1]), name = \"weight\")\n",
    "    b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "\n",
    "#モデル\n",
    "with tf.name_scope('model'):\n",
    "    pred = tf.add(tf.matmul(X, W), b) #matmulは行列の積\n",
    "\n",
    "#損失関数\n",
    "with tf.name_scope('loss'):\n",
    "    # Mean squared error\n",
    "    loss = tf.reduce_mean(tf.square(pred - Y))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#決定係数(R2)\n",
    "with tf.name_scope('r2'):\n",
    "    r2 = 1 - (tf.reduce_sum(tf.square(Y - pred)) / tf.reduce_sum(tf.square(Y - tf.reduce_mean(Y))))\n",
    "    tf.summary.scalar('r2', r2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # ログの設定\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"boston_log\", sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())#変数初期化\n",
    "    \n",
    "    for i in range(10000):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i != 0 and i % 200 == 0: # 200ステップごとに精度を出力\n",
    "            train_summary, train_loss, train_r2 = sess.run([summary, loss, r2], feed_dict={X: train_X, Y:train_Y})# コストと精度を出力\n",
    "            writer.add_summary(train_summary, i) #summaryの更新\n",
    "            \n",
    "            print(\"Step:\", '%04d' % (i), \"loss=\", \"{:.9f}\".format(train_loss), \"r2=\", \"{:.9f}\".format(train_r2), \"W=\", sess.run(W), \"b=\", sess.run(b))            \n",
    "            \n",
    "    training_cost, training_r2 = sess.run([loss,r2], feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"Training r2=\", training_r2, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'data/X', defined at:\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-5fa4b71e6af0>\", line 25, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-265f6c313127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 200ステップごとに精度を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mtrain_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_r2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# コストと精度を出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#summaryの更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'data/X', defined at:\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-33-5fa4b71e6af0>\", line 25, in <module>\n    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 4105, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\OSK-84\\Anaconda3\\envs\\tensorflow13\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'data/X' with dtype float and shape [?,13]\n\t [[Node: data/X = Placeholder[dtype=DT_FLOAT, shape=[?,13], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#ボストンデータ読み込み\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "df['target'] = boston.target\n",
    "\n",
    "#学習データ準備\n",
    "f_num = df.shape[1] - 1\n",
    "train_X = np.array(df.iloc[:, :f_num])\n",
    "train_Y = np.array(df.iloc[:, f_num: f_num + 1])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "#正規化\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_X)\n",
    "train_X = ss.transform(train_X)\n",
    "\n",
    "#プレースホルダー\n",
    "with tf.name_scope('data'):\n",
    "    X = tf.placeholder(tf.float32, shape = [None, f_num ], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, name = \"Y\")\n",
    "\n",
    "#変数（パラメータ）\n",
    "with tf.name_scope('parameter'):\n",
    "    W = tf.Variable(tf.zeros([f_num, 1]), name = \"weight\")\n",
    "    b = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "\n",
    "#モデル\n",
    "with tf.name_scope('model'):\n",
    "    pred = tf.add(tf.matmul(X, W), b) #matmulは行列の積\n",
    "\n",
    "#損失関数\n",
    "with tf.name_scope('loss'):\n",
    "    # Mean squared error\n",
    "    loss = tf.reduce_mean(tf.square(pred - Y))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#決定係数(R2)\n",
    "with tf.name_scope('r2'):\n",
    "    r2 = 1 - (tf.reduce_sum(tf.square(Y - pred)) / tf.reduce_sum(tf.square(Y - tf.reduce_mean(Y))))\n",
    "    tf.summary.scalar('r2', r2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # ログの設定\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"boston_log\", sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())#変数初期化\n",
    "    \n",
    "    for i in range(1200):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i != 0 and i % 200 == 0: # 200ステップごとに精度を出力\n",
    "            train_summary, train_loss, train_r2 = sess.run([summary, loss, r2], feed_dict={X: train_X, Y:train_Y})# コストと精度を出力\n",
    "            writer.add_summary(train_summary, i) #summaryの更新\n",
    "            \n",
    "            print(\"Step:\", '%04d' % (i), \"loss=\", \"{:.9f}\".format(train_loss), \"r2=\", \"{:.9f}\".format(train_r2), \"W=\", sess.run(W), \"b=\", sess.run(b))            \n",
    "            \n",
    "    training_cost, training_r2 = sess.run([loss,r2], feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"Training r2=\", training_r2, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
